{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7049be18-2025-4ed0-b06f-b0269fbdbb93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "import pickle\n",
    "\n",
    "from textattack.models.wrappers import ModelWrapper\n",
    "from textattack.datasets import HuggingFaceDataset\n",
    "from textattack.attack_recipes import PWWSRen2019\n",
    "from textattack import Attacker\n",
    "from textattack.datasets import HuggingFaceDataset\n",
    "from textattack.attack_recipes import PWWSRen2019\n",
    "from textattack import Attacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9033dc5d-ad95-400b-95af-79a713169aac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import textattack\n",
    "from model_wrapper import ModelWrapper\n",
    "\n",
    "from models import model_1 as mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a81f4e-44c5-4d2f-a422-c6f8f4e2b81c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ac3741-10da-4013-8925-1f0d8ce411a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PyTorchModelWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3916c7f2-9acc-4cf6-9447-1cb42d824813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PyTorchModelWrapper(ModelWrapper):\n",
    "    \"\"\"Loads a PyTorch model (`nn.Module`) and tokenizer.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): PyTorch model\n",
    "        tokenizer: tokenizer whose output can be packed as a tensor and passed to the model.\n",
    "            No type requirement, but most have `tokenizer` method that accepts list of strings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, tokenizer):\n",
    "        if not isinstance(model, torch.nn.Module):\n",
    "            raise TypeError(\n",
    "                f\"PyTorch model must be torch.nn.Module, got type {type(model)}\"\n",
    "            )\n",
    "\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def to(self, device):\n",
    "        self.model.to(device)\n",
    "\n",
    "    def __call__(self, text_input_list, batch_size=32):\n",
    "        model_device = next(self.model.parameters()).device\n",
    "        ############################################################ Change 1\n",
    "        ids = self.tokenizer(text_input_list, return_tensors=\"pt\", padding=True)\n",
    "        ids = ids.to(model_device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = textattack.shared.utils.batch_model_predict(\n",
    "                self.model, ids, batch_size=batch_size\n",
    "            )\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def get_grad(self, text_input, loss_fn=CrossEntropyLoss()):\n",
    "        \"\"\"Get gradient of loss with respect to input tokens.\n",
    "\n",
    "        Args:\n",
    "            text_input (str): input string\n",
    "            loss_fn (torch.nn.Module): loss function. Default is `torch.nn.CrossEntropyLoss`\n",
    "        Returns:\n",
    "            Dict of ids, tokens, and gradient as numpy array.\n",
    "        \"\"\"\n",
    "\n",
    "        if not hasattr(self.model, \"get_input_embeddings\"):\n",
    "            raise AttributeError(\n",
    "                f\"{type(self.model)} must have method `get_input_embeddings` that returns `torch.nn.Embedding` object that represents input embedding layer\"\n",
    "            )\n",
    "        if not isinstance(loss_fn, torch.nn.Module):\n",
    "            raise ValueError(\"Loss function must be of type `torch.nn.Module`.\")\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        embedding_layer = self.model.get_input_embeddings()\n",
    "        original_state = embedding_layer.weight.requires_grad\n",
    "        embedding_layer.weight.requires_grad = True\n",
    "\n",
    "        emb_grads = []\n",
    "\n",
    "        def grad_hook(module, grad_in, grad_out):\n",
    "            emb_grads.append(grad_out[0])\n",
    "\n",
    "        emb_hook = embedding_layer.register_backward_hook(grad_hook)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        model_device = next(self.model.parameters()).device\n",
    "        \n",
    "        ######################################################### Change 2\n",
    "        ids = self.tokenizer(text_input_list, return_tensors=\"pt\", padding=True)\n",
    "        ids = ids.to(model_device)\n",
    "\n",
    "        predictions = self.model(ids)\n",
    "\n",
    "        output = predictions.argmax(dim=1)\n",
    "        loss = loss_fn(predictions, output)\n",
    "        loss.backward()\n",
    "\n",
    "        # grad w.r.t to word embeddings\n",
    "\n",
    "        # Fix for Issue #601\n",
    "\n",
    "        # Check if gradient has shape [max_sequence,1,_] ( when model input in transpose of input sequence)\n",
    "\n",
    "        if emb_grads[0].shape[1] == 1:\n",
    "            grad = torch.transpose(emb_grads[0], 0, 1)[0].cpu().numpy()\n",
    "        else:\n",
    "            # gradient has shape [1,max_sequence,_]\n",
    "            grad = emb_grads[0][0].cpu().numpy()\n",
    "\n",
    "        embedding_layer.weight.requires_grad = original_state\n",
    "        emb_hook.remove()\n",
    "        self.model.eval()\n",
    "\n",
    "        output = {\"ids\": ids[0].tolist(), \"gradient\": grad}\n",
    "\n",
    "        return output\n",
    "\n",
    "    def _tokenize(self, inputs):\n",
    "        \"\"\"Helper method that for `tokenize`\n",
    "        Args:\n",
    "            inputs (list[str]): list of input strings\n",
    "        Returns:\n",
    "            tokens (list[list[str]]): List of list of tokens as strings\n",
    "        \"\"\"\n",
    "        return [self.tokenizer.convert_ids_to_tokens(self.tokenizer(x)) for x in inputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0580a9c-44b6-4bc9-9cd1-5bcdb0c19f15",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Self Tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "095be769-64d7-428e-9560-0fdfbfa71a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ad_transformer(nn.Module):\n",
    "  def __init__(self, d_model, nhead, nlayer, max_token, embedding, device = \"cuda\"):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.max_token = max_token\n",
    "\n",
    "    self.embedding = torch.tensor(embedding)\n",
    "\n",
    "    encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True, device = device)\n",
    "    self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=nlayer).to(\"cuda\")\n",
    "    self.linear_out = nn.Linear(d_model * max_token, 2)\n",
    "\n",
    "  def forward(self, input_str, device = \"cuda\"):\n",
    "\n",
    "    #if type(input_str) != list:\n",
    "    #    raise TypeError(\"Self Error : Invalid Input !!!\")\n",
    "      \n",
    "    input = input_str[\"input_ids\"]\n",
    "\n",
    "    ## Tokens to embeding\n",
    "    input_embd = torch.zeros(len(input), self.max_token, self.d_model)\n",
    "    \n",
    "    input_embd = input_embd + self.embedding[0]   ### Padding\n",
    "      \n",
    "    for batch_num in range(len(input)):\n",
    "        for i in range(len(input[batch_num])):\n",
    "            input_embd[batch_num][i] = self.embedding[input[batch_num][i]]\n",
    "    input_embd = input_embd.to(device)\n",
    "    \n",
    "    out1 = self.transformer_encoder(input_embd)\n",
    "    return self.linear_out(out1.reshape(len(out1), self.max_token * self.d_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a031a345-3045-460a-b645-722db0226563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_model = 768\n",
    "max_token = 50\n",
    "nhead = 12\n",
    "nlayer = 6\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d85c977d-8aba-460e-afb0-474b636ee2e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"bert_embedding.pkl\", \"rb\") as file:\n",
    "    embd = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f2e89fd2-a358-4b23-b041-32c94e2ca1b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ad_transformer(d_model,nhead, nlayer, max_token, embd, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "89254143-a950-4897-aba7-4d3cdca9e44f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d9c9aef0-14e5-499a-b448-1023ca198a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_input = tokenizer.batch_encode_plus([\"Hi\", \"Bye\"], return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8516741b-af6f-49d3-9138-21921bd73a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 7632,  102],\n",
       "        [ 101, 9061,  102]], device='cuda:0')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f7d8a-22d8-41a2-8cfe-dee7dad793fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c1b519d4-62eb-41ed-8793-38bade74202c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0471,  0.3120],\n",
       "        [-0.0164,  0.3773]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(enc_input, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61c33c6-8611-41cb-88e6-e07b450f23b8",
   "metadata": {},
   "source": [
    "### Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a7a14008-a471-4843-9de0-2bc4b10a7ed2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wrapper = PyTorchModelWrapper(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6236354f-9adb-4bce-8ed8-87a77029d1fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/aamod_thakur/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "textattack: Unknown if model of class <class '__main__.ad_transformer'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    }
   ],
   "source": [
    "#dataset = HuggingFaceDataset(\"sms_spam\",dataset_columns=[\"text\",\"label\"], shuffle=True)\n",
    "dataset = HuggingFaceDataset(\"rotten_tomatoes\", None, \"test\", shuffle=True)\n",
    "attack = PWWSRen2019.build(wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e2aef9de-c124-4d18-9f35-0e3d8c18f42c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('text',\n",
       "               'lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .')]),\n",
       " 1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1db4eff4-ba2d-4152-b454-4cc55e09f919",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attacker = Attacker(attack, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "08fb9cdd-6e86-48a7-8e44-6ea2868862f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  weighted-saliency\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapWordNet\n",
      "  (constraints): \n",
      "    (0): RepeatModification\n",
      "    (1): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 1 / 2:  20%|██████████████                                                        | 2/10 [00:00<00:00, 22.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[Negative (60%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[Positive (62%)]] --> [[[FAILED]]]\n",
      "\n",
      "consistently clever and suspenseful .\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 1 / 2 / 4:  40%|████████████████████████████                                          | 4/10 [00:00<00:00,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "[[Positive (58%)]] --> [[Negative (53%)]]\n",
      "\n",
      "it's like a \" big chill \" reunion of the baader-meinhof gang , only these [[guys]] are more harmless [[pranksters]] than political activists .\n",
      "\n",
      "it's like a \" big chill \" reunion of the baader-meinhof gang , only these [[rib]] are more harmless [[cut-up]] than political activists .\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "[[Negative (56%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the story gives ample opportunity for large-scale action and suspense , which director shekhar kapur supplies with tremendous skill .\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 1 / 2 / 5:  50%|███████████████████████████████████                                   | 5/10 [00:00<00:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "[[Positive (57%)]] --> [[Negative (51%)]]\n",
      "\n",
      "red dragon \" [[never]] [[cuts]] corners .\n",
      "\n",
      "red dragon \" [[ne'er]] [[prune]] corners .\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 1 / 2 / 6:  60%|██████████████████████████████████████████                            | 6/10 [00:01<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "[[Positive (59%)]] --> [[Negative (66%)]]\n",
      "\n",
      "fresnadillo has something serious to say about the ways in which extravagant chance can [[distort]] our perspective and throw us off the path of good sense .\n",
      "\n",
      "fresnadillo has something serious to say about the ways in which extravagant chance can [[wring]] our perspective and throw us off the path of good sense .\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 1 / 3 / 9:  90%|███████████████████████████████████████████████████████████████       | 9/10 [00:01<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "[[Positive (59%)]] --> [[Negative (55%)]]\n",
      "\n",
      "[[throws]] in enough clever and unexpected twists to make the formula feel fresh .\n",
      "\n",
      "[[bedevil]] in enough clever and unexpected twists to make the formula feel fresh .\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "[[Positive (68%)]] --> [[Negative (52%)]]\n",
      "\n",
      "weighty and [[ponderous]] but every bit as filling as the treat of the title .\n",
      "\n",
      "weighty and [[heavy]] but every bit as filling as the treat of the title .\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "[[Negative (59%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "a real audience-pleaser that will strike a chord with anyone who's ever waited in a doctor's office , emergency room , hospital bed or insurance company office .\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 2 / 3 / 10: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "[[Positive (61%)]] --> [[[FAILED]]]\n",
      "\n",
      "generates an enormous feeling of empathy for its characters .\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 5      |\n",
      "| Number of failed attacks:     | 2      |\n",
      "| Number of skipped attacks:    | 3      |\n",
      "| Original accuracy:            | 70.0%  |\n",
      "| Accuracy under attack:        | 20.0%  |\n",
      "| Attack success rate:          | 71.43% |\n",
      "| Average perturbed word %:     | 13.74% |\n",
      "| Average num. words per input: | 15.4   |\n",
      "| Avg num queries:              | 111.0  |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f67e91fafb0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f67e91fb1f0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f67e299d840>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f681ed47160>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f67cebfe710>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f67e91fb2e0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f67cebff310>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f67cebff700>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f67cebff220>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f67cebff6a0>]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacker.attack_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85db722d-9611-4aaa-98d0-450653bbd8df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "27d18bff-d015-429a-8ff2-f0b92b7ea323",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 14 09:55:52 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       On  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   62C    P0              32W /  70W |    651MiB / 15360MiB |     18%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      4165      C   /opt/conda/bin/python                       646MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c447e937-f2ef-438b-a96b-b402d1dbd13d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
